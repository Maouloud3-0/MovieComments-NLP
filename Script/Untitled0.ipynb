{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"lRGevu8jNgSV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710857841345,"user_tz":-60,"elapsed":42769,"user":{"displayName":"Rêve Kemy Diavou Diavou","userId":"12983391272185238233"}},"outputId":"d13740bc-ee68-4ab0-c2d4-35d54cbe0561"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/My Drive\")\n","print(os.getcwd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMkZuR6HFEPK","executionInfo":{"status":"ok","timestamp":1710857940981,"user_tz":-60,"elapsed":316,"user":{"displayName":"Rêve Kemy Diavou Diavou","userId":"12983391272185238233"}},"outputId":"837e73d2-d4fd-4e14-ae98-53d1b23be336"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in function getcwd>\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pj62gIcQM6fj"},"outputs":[],"source":["\n","import pandas as pd #manipulation et l'analyse de données tabulaires\n","import re # manipulation de chaînes de caractères\n","import spacy #  traitement du langage naturel (NLP)\n","from textblob import TextBlob # traitement du langage naturel (NLP) qui offre une interface simple\n","import emoji # travailler avec des emojis\n","from textblob import Blobber #  étend les fonctionnalités de TextBlob pour la langue française\n","from textblob_fr import PatternTagger, PatternAnalyzer\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder # convertir des valeurs de texte en valeurs numériques\n","\n","\n","\n","df = pd.read_csv(\"C:/Users/W10/Downloads/sae n/commentaires_films_series.csv\")\n","\n","# Charger le modèle de langue française\n","nlp = spacy.load('fr_core_news_sm')\n","# modèle pré-entraîné qui comprend des fonctionnalités telles que la\n","# tokenisation, l'étiquetage grammatical, la reconnaissance d'entités\n","# nommées, la lemmatisation, etc\n","\n","# Fonction pour compter les émoticônes\n","def compter_emoticones(texte):\n","    return emoji.emoji_count(texte)\n","# compter_emoticones qui prend une chaîne de caractères (texte)\n","# en entrée et compte le nombre d'émoticônes présentes dans cette\n","# chaîne\n","\n","\n","# Fonction pour compter les mots\n","def compter_mots(texte):\n","    return len(texte.split())\n","# compter_mots qui prend une chaîne de caractères (texte) en entrée et\n","# compte le nombre de mots présents dans cette chaîne\n","\n","# Fonction pour compter les verbes, entités nommées et adjectifs\n","def compter_pos_entites(texte):\n","    doc = nlp(texte)\n","    nb_verbes = len([token for token in doc if token.pos_ == \"VERB\"])\n","    nb_entites = len(doc.ents)\n","    nb_adjectifs = len([token for token in doc if token.pos_ == \"ADJ\"])\n","    return nb_verbes, nb_entites, nb_adjectifs\n","# cette ligne retourne un tuple contenant le nombre de verbes,\n","# d'entités nommées et d'adjectifs trouvés dans le texte\n","\n","\n","import spacy\n","from textblob import TextBlob\n","\n","# Chargez le modèle de langue français de spaCy\n","nlp = spacy.load('fr_core_news_sm')\n","\n","def temps_dominant(texte):\n","    doc = nlp(texte)\n","    temps_verbes = {'present': 0, 'past': 0, 'future': 0}\n","\n","    for token in doc:\n","        if token.pos_ == 'VERB' or token.pos_ == 'AUX':\n","            if token.morph.get(\"Tense\") == ['Pres']:\n","                temps_verbes['present'] += 1\n","            elif token.morph.get(\"Tense\") == ['Past']:\n","                temps_verbes['past'] += 1\n","            elif token.morph.get(\"Mood\") == ['Cnd'] or token.text.lower() in ['sera', 'auront', 'iront']:\n","                temps_verbes['future'] += 1\n","\n","    # Trouvez le temps le plus utilisé et renvoyez-le\n","    return max(temps_verbes, key=temps_verbes.get), temps_verbes\n","\n","# lorsqu'on appelle cette fonction avec une chaîne de caractères en\n","# entrée, elle retourne le temps verbal dominant dans le texte ainsi\n","# que le décompte de chaque temps verbal\n","\n","\n","from textblob import TextBlob\n","# utilisée pour l'analyse de sentiment\n","\n","def analyser_sentiment_verbes(texte):\n","    doc = nlp(texte)\n","    sentiments = {'positifs': 0, 'negatifs': 0}\n","\n","    for token in doc:\n","        if token.pos_ == 'VERB':\n","            verdict = TextBlob(str(token))\n","            if verdict.sentiment.polarity > 0:\n","                sentiments['positifs'] += 1\n","            elif verdict.sentiment.polarity < 0:\n","                sentiments['negatifs'] += 1\n","\n","    return sentiments\n","# retourne le dictionnaire sentiments contenant le nombre de verbes\n","# positifs et négatifs trouvés dans le texte\n","\n","# cette fonction avec une chaîne de caractères en entrée, elle\n","#retourne un dictionnaire contenant le nombre de verbes positifs et\n","# négatifs dans le texte.\n","\n","# Assurez-vous que 'nlp' est bien défini et initialisé, par exemple:\n","# nlp = spacy.load('fr_core_news_sm') ou le modèle de votre choix\n","\n","\n","\n","# Application des fonctions\n","df['Nb_Mots'] = df['Commentaire'].apply(compter_mots)\n","df['Nb_Emoticones'] = df['Commentaire'].apply(compter_emoticones)\n","\n","# Compter les verbes, entités nommées et adjectifs et les ajouter au DataFrame\n","df[['Nb_Verbes', 'Nb_Entites_Nommees', 'Nb_Adjectifs']] = df['Commentaire'].apply(\n","    lambda x: pd.Series(compter_pos_entites(x))\n",")\n","\n","# Appliquer les fonctions sur le DataFrame\n","# Appliquer la fonction modifiée pour obtenir le temps dominant et le décompte des verbes\n","df['Temps_Dominant'], df['Compte_Temps'] = zip(*df['Commentaire'].apply(temps_dominant))\n","\n","# Créer des colonnes individuelles pour chaque temps à partir du dictionnaire retourné\n","df['Nb_Verbes_Present'] = df['Compte_Temps'].apply(lambda x: x['present'])\n","df['Nb_Verbes_Past'] = df['Compte_Temps'].apply(lambda x: x['past'])\n","df['Nb_Verbes_Future'] = df['Compte_Temps'].apply(lambda x: x['future'])\n","\n","# Vous pouvez ensuite supprimer la colonne 'Compte_Temps' si elle n'est pas nécessaire\n","df.drop(columns=['Compte_Temps'], inplace=True)\n","\n","# Appliquez la fonction à votre DataFrame\n","df['Sentiment_Verbes'] = df['Commentaire'].apply(analyser_sentiment_verbes)\n","\n","\n","# Afficher le DataFrame pour vérifier\n","df\n","\n","\n","# Enregistrer le DataFrame en fichier CSV\n","df.to_csv('C:/Users/gaous/Desktop/BUT 3/S6/R6 06 machine learning texte/commentaire_avec_critères.csv', index=False)\n","\n","df.columns\n","\n","#\n","# Créer la colonne cible en fonction du score\n","df['Cible'] = (df['Note'] > 3.5).astype(int)\n","# Initialiser le LabelEncoder\n","le = LabelEncoder()\n","\n","# Supposons que 'Colonne_Catégorielle' est le nom de votre colonne catégorielle\n","df['Temps_Dominant'] = le.fit_transform(df['Temps_Dominant'])\n","\n","# Sélectionner les caractéristiques pour la régression logistique\n","\n","X = df[['Nb_Mots', 'Nb_Emoticones', 'Nb_Verbes','Nb_Entites_Nommees', 'Nb_Adjectifs',\n","        'Temps_Dominant','Nb_Emoticones', 'Nb_Verbes_Present', 'Nb_Verbes_Past', 'Nb_Verbes_Future']]\n","y = df['Cible']\n","\n","# Supposons que 'X' sont les caractéristiques et 'y' est la variable cible.\n","# Diviser les données, en utilisant à la fois 'train_size' et 'test_size', avec stratification et mélange\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.17,     # 20% des données comme ensemble de test\n","    train_size=0.83,    # 80% des données comme ensemble d'entraînement\n","    random_state=42,   # Pour la reproductibilité\n","    shuffle=True,      # Mélanger les données avant de diviser\n","    stratify=y         # Pour conserver la proportion des classes dans les splits\n",")\n","\n","# Créer et entraîner le modèle de régression logistique\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Prédire les valeurs pour l'ensemble de test\n","y_pred = model.predict(X_test)\n","\n","# Calculer la précision du modèle\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"L'exactitude du modèle est : {accuracy}\")\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from sklearn.metrics import roc_auc_score, roc_curve, log_loss\n","\n","# Matrice de confusion\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(f\"Matrice de confusion :\\n{conf_matrix}\")\n","\n","# Rapport de classification\n","class_report = classification_report(y_test, y_pred)\n","print(f\"Rapport de classification :\\n{class_report}\")\n","\n","# Précision, Rappel, Score F1\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","print(f\"Précision : {precision}\")\n","print(f\"Rappel : {recall}\")\n","print(f\"Score F1 : {f1}\")\n","\n","# ROC AUC\n","y_pred_proba = model.predict_proba(X_test)[:,1]\n","roc_auc = roc_auc_score(y_test, y_pred_proba)\n","print(f\"ROC AUC : {roc_auc}\")\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","# Prédictions de probabilité pour la classe positive\n","y_pred_proba = model.predict_proba(X_test)[:,1]\n","\n","# Calcul des taux de vrais positifs et faux positifs\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n","\n","# Calcul de l'aire sous la courbe (AUC)\n","roc_auc = auc(fpr, tpr)\n","\n","# Tracer la courbe ROC\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","\n","# Log Loss\n","logloss = log_loss(y_test, y_pred_proba)\n","print(f\"Log Loss : {logloss}\")\n"]},{"cell_type":"markdown","source":["Deuxième partie de la SAE"],"metadata":{"id":"4z9C4nppCgwI"}},{"cell_type":"markdown","source":["Charger les données"],"metadata":{"id":"NRZrkK_IC5dS"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"RyG-LsPMDrTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/My Drive/SAE 6 EMS 1 Modélisation statistique IA sur texte/sae/commentaire_avec_critères.csv\")"],"metadata":{"id":"koCD8-ECCk3V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vérification du chargement"],"metadata":{"id":"1hpb05ChC_xT"}},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vXojE2sWDBy2","executionInfo":{"status":"ok","timestamp":1710858347365,"user_tz":-60,"elapsed":423,"user":{"displayName":"Rêve Kemy Diavou Diavou","userId":"12983391272185238233"}},"outputId":"cdafc85f-a3cd-4fbd-ded4-1f7981db7458"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    URL  Note  \\\n","0     https://www.allocine.fr/film/fichefilm-267218/...   0.5   \n","1     https://www.allocine.fr/film/fichefilm-267218/...   1.5   \n","2     https://www.allocine.fr/film/fichefilm-267218/...   1.0   \n","3     https://www.allocine.fr/film/fichefilm-267218/...   1.0   \n","4     https://www.allocine.fr/film/fichefilm-267218/...   0.5   \n","...                                                 ...   ...   \n","8821  https://www.allocine.fr/series/ficheserie-290/...   5.0   \n","8822  https://www.allocine.fr/series/ficheserie-290/...   5.0   \n","8823  https://www.allocine.fr/series/ficheserie-290/...   5.0   \n","8824  https://www.allocine.fr/series/ficheserie-290/...   4.0   \n","8825  https://www.allocine.fr/series/ficheserie-290/...   5.0   \n","\n","                                            Commentaire  Nb_Mots  \\\n","0     Alors comment dire...En fait non, il n'y a pas...       64   \n","1     L'équipe de \"Sound of Freedom\" a fini par adme...      114   \n","2     Je ne sais pas pkoi je dois rédiger une critiq...       43   \n","3     Tout n'est que cliché dans ce film : un scénar...       78   \n","4     Vraiment pas fou pour un premier rendez vous a...       23   \n","...                                                 ...      ...   \n","8821  Même pas besoin de critique, les Simpson parle...       10   \n","8822  merci tout simplement ! rien à dire qui n'est ...       23   \n","8823  Une série toujours aussi marante qui en 25 ans...       15   \n","8824  Contrairement aux apparences, série bourrée de...       17   \n","8825  Une série animée vraiment sympa, quoi de mieux...       27   \n","\n","      Nb_Emoticones  Nb_Verbes  Nb_Entites_Nommees  Nb_Adjectifs  \\\n","0                 0          8                   2             7   \n","1                 0         14                   1            11   \n","2                 0          7                   0             7   \n","3                 0          8                   1             9   \n","4                 1          1                   1             4   \n","...             ...        ...                 ...           ...   \n","8821              0          1                   1             0   \n","8822              0          2                   1             1   \n","8823              0          1                   0             1   \n","8824              0          2                   0             4   \n","8825              0          3                   0             3   \n","\n","     Temps_Dominant  Nb_Verbes_Present  Nb_Verbes_Past  Nb_Verbes_Future  \n","0           present                  6               3                 0  \n","1           present                  8               4                 0  \n","2           present                  4               2                 0  \n","3           present                  6               3                 0  \n","4           present                  2               1                 0  \n","...             ...                ...             ...               ...  \n","8821        present                  1               0                 0  \n","8822        present                  2               1                 0  \n","8823        present                  1               1                 0  \n","8824        present                  1               0                 0  \n","8825           past                  1               2                 0  \n","\n","[8826 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-a279a35d-6042-496a-81b1-ee1938de0f1d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL</th>\n","      <th>Note</th>\n","      <th>Commentaire</th>\n","      <th>Nb_Mots</th>\n","      <th>Nb_Emoticones</th>\n","      <th>Nb_Verbes</th>\n","      <th>Nb_Entites_Nommees</th>\n","      <th>Nb_Adjectifs</th>\n","      <th>Temps_Dominant</th>\n","      <th>Nb_Verbes_Present</th>\n","      <th>Nb_Verbes_Past</th>\n","      <th>Nb_Verbes_Future</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.allocine.fr/film/fichefilm-267218/...</td>\n","      <td>0.5</td>\n","      <td>Alors comment dire...En fait non, il n'y a pas...</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>present</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.allocine.fr/film/fichefilm-267218/...</td>\n","      <td>1.5</td>\n","      <td>L'équipe de \"Sound of Freedom\" a fini par adme...</td>\n","      <td>114</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>present</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.allocine.fr/film/fichefilm-267218/...</td>\n","      <td>1.0</td>\n","      <td>Je ne sais pas pkoi je dois rédiger une critiq...</td>\n","      <td>43</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>present</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://www.allocine.fr/film/fichefilm-267218/...</td>\n","      <td>1.0</td>\n","      <td>Tout n'est que cliché dans ce film : un scénar...</td>\n","      <td>78</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>present</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.allocine.fr/film/fichefilm-267218/...</td>\n","      <td>0.5</td>\n","      <td>Vraiment pas fou pour un premier rendez vous a...</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>present</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8821</th>\n","      <td>https://www.allocine.fr/series/ficheserie-290/...</td>\n","      <td>5.0</td>\n","      <td>Même pas besoin de critique, les Simpson parle...</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>present</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8822</th>\n","      <td>https://www.allocine.fr/series/ficheserie-290/...</td>\n","      <td>5.0</td>\n","      <td>merci tout simplement ! rien à dire qui n'est ...</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>present</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8823</th>\n","      <td>https://www.allocine.fr/series/ficheserie-290/...</td>\n","      <td>5.0</td>\n","      <td>Une série toujours aussi marante qui en 25 ans...</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>present</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8824</th>\n","      <td>https://www.allocine.fr/series/ficheserie-290/...</td>\n","      <td>4.0</td>\n","      <td>Contrairement aux apparences, série bourrée de...</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>present</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8825</th>\n","      <td>https://www.allocine.fr/series/ficheserie-290/...</td>\n","      <td>5.0</td>\n","      <td>Une série animée vraiment sympa, quoi de mieux...</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>past</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8826 rows × 12 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a279a35d-6042-496a-81b1-ee1938de0f1d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a279a35d-6042-496a-81b1-ee1938de0f1d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a279a35d-6042-496a-81b1-ee1938de0f1d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cc2dc4eb-0a75-44d1-b090-fdb9b0f97fd5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc2dc4eb-0a75-44d1-b090-fdb9b0f97fd5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cc2dc4eb-0a75-44d1-b090-fdb9b0f97fd5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8826,\n  \"fields\": [\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"https://www.allocine.fr/film/fichefilm-267218/critiques/spectateurs/\",\n          \"https://www.allocine.fr/series/ficheserie-322/critiques/\",\n          \"https://www.allocine.fr/series/ficheserie-11303/critiques/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Note\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8689932172424841,\n        \"min\": 0.5,\n        \"max\": 5.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.5,\n          1.5,\n          4.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Commentaire\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8817,\n        \"samples\": [\n          \"dommagecomment ce casting de qualit\\u00e9 a t-il pu s'embarquer dans un tel naufrage? un sc\\u00e9nario aussi ultra convenu que insipide : entre d\\u00e9j\\u00e0 vu et une histoire qui part dans tous les sens sans vraiment de base solide,film sans int\\u00e9r\\u00eat quel dommage\",\n          \"Un tr\\u00e8s bon moment pass\\u00e9 en famille.On oublie la m\\u00e9diocrit\\u00e9 d'Ast\\u00e9rix aux jeux Olympiques et on revient \\u00e0 un bon filmTr\\u00e8s bonne interpr\\u00e9tation globale des acteurs de m\\u00e9tiers, trop nombreux pour les citer.Le niveau des guests est un peu en dessous, mais ils sont bien exploit\\u00e9s et permettent de toucher un public plus large et ultra connect\\u00e9s aux r\\u00e9seaux sociaux (Orelsan , Angele ou Zlatan).\",\n          \"N'ayant pas c\\u00e9d\\u00e9 de suite \\u00e0 me rendre au cin\\u00e9ma voir le dernier Ast\\u00e9rix. J'ai pr\\u00e9f\\u00e9r\\u00e9 le voir plus tranquillement en salle en province.Le choc, le coup sur la t\\u00eate.Comment est il possible de sortir en 2023 un film aussi vide ? Des blagues carambar, des mimiques de gosses. Des acteurs en roue libre. Rien n'est \\u00e0 sauver , Une succession de cam\\u00e9o ou d'ailleurs je n'ai pas du reconnaitre la plupart des vedettes. J'ai eu le sentiment de voir un film pour les 3 \\u00e0 5 ans.Ast\\u00e9rix mauvais, Ob\\u00e9lix mauvais , Marion Cotillard et son rire cata...Jos\\u00e9 Garcia en perroquet.Une demie \\u00e9toile pour sauver l'honneur pour Vincent Cassel, qui est le seul \\u00e0 tenter d'\\u00e9coper \\u00e0 bord de ce naufrage.Je crois que c'est sans h\\u00e9siter le plus mauvais film que j'ai vu ces 20 derni\\u00e8res ann\\u00e9es. Et une chose certaine , je n'irait plus jamais voir de film d'Ast\\u00e9rix en live.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Mots\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112,\n        \"min\": 1,\n        \"max\": 4496,\n        \"num_unique_values\": 504,\n        \"samples\": [\n          141,\n          487,\n          434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Emoticones\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 95,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0,\n          1,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Verbes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 595,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          107,\n          43,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Entites_Nommees\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 377,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          20,\n          2,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Adjectifs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 292,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          58,\n          7,\n          73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temps_Dominant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"present\",\n          \"past\",\n          \"future\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Verbes_Present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 474,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          62,\n          6,\n          82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Verbes_Past\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 151,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          29,\n          16,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nb_Verbes_Future\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Chargement des packages"],"metadata":{"id":"pvQBZYGRG2sg"}},{"cell_type":"code","source":["import numpy as np\n","import collections\n","import os, sys\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from keras.layers import Embedding\n","from keras.optimizers import Adam\n","from keras.losses import sparse_categorical_crossentropy\n","from keras.callbacks import EarlyStopping\n","from keras.saving import load_model"],"metadata":{"id":"LhycrAu7G6gj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chargement du modèle"],"metadata":{"id":"gifFublaH3Ca"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"metadata":{"id":"Bl8ZtxbwMvYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chemin vers le fichier du modèle pré-entraîné\n","chemin_vers_modele = \"/content/drive/My Drive/SAE 6 EMS 1 Modélisation statistique IA sur texte/sae/tf_model.h5\""],"metadata":{"id":"9YGvRHL4M3HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Charger le modèle pré-entraîné\n","modele_charge = load_model(\"/content/drive/My Drive/SAE 6 EMS 1 Modélisation statistique IA sur texte/sae/tf_model.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"gXLOoyTiH5cB","executionInfo":{"status":"error","timestamp":1710860258172,"user_tz":-60,"elapsed":636,"user":{"displayName":"Rêve Kemy Diavou Diavou","userId":"12983391272185238233"}},"outputId":"9c9c36e7-8c8e-4cd2-e663-a8c27575ce35"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7cf7250ecbe0>.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-db56bb7e7bf4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Charger le modèle pré-entraîné\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodele_charge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SAE 6 EMS 1 Modélisation statistique IA sur texte/sae/tf_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0;34mf\"No model config found in the file at {filepath}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7cf7250ecbe0>."]}]},{"cell_type":"code","source":["# Afficher les détails du modèle\n","modele_charge.summary()"],"metadata":{"id":"PyZPnxjlNQC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","from keras.layers import Bidirectional\n","from keras.layers import GRU\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.layers import Activation\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from keras.optimizers import Adam\n","\n","learning_rate= 1e-3\n","inputs = Input(shape=(None,))\n","embedding = Embedding(input_dim=english_vocab_size+1,output_dim=32,\n","input_length=tokenized_english_sentences.shape[1])(inputs)\n","encoder = Bidirectional(GRU(256, return_sequences=False))(embedding)\n","context = RepeatVector(max_len_sentence_french)(encoder)\n","decoder = Bidirectional(GRU(256, return_sequences=True))(context)\n","dense = TimeDistributed(Dense(french_vocab_size+1))(decoder)\n","outputs = Activation(\"softmax\")(dense)\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(loss=sparse_categorical_crossentropy, optimizer=Adam(learning_rate),\n","metrics=['accuracy'])\n","model.summary()"],"metadata":{"id":"mohw9fRUHh97"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Faire tourner le programme"],"metadata":{"id":"JI3nTfT4HqNl"}},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","history = model.fit(tokenized_english_sentences,\n","tokenized_french_sentences, batch_size=1024, epochs=40,\n","validation_split=0.2,\n","callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n","model.save(\"/content/drive/My Drive/ML S6 BUT 3/my_model.keras_2\")"],"metadata":{"id":"gwrawWzdHn8B"},"execution_count":null,"outputs":[]}]}